{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b48b374",
   "metadata": {},
   "source": [
    "# Age and Gender Recognition\n",
    "\n",
    "### github.com/rafaroman18\n",
    "\n",
    "This project consist of classifying in real time the gender of a person and their age. We will be using a dataset of faces and a library of python to activate the camera of our laptop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdacb75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import cv2 as cv\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import keras.applications\n",
    "\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148c654f",
   "metadata": {},
   "source": [
    "First of all we will create a model to predict the gender and age of the people in the camera. We will train this model with a face dataset and we will use a pretrained model: XCEPTION. \n",
    "\n",
    "We will use the UTKFace Dataset, so we have to create a function to transform the images locally into a tensorflow dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06ae445",
   "metadata": {},
   "source": [
    "## MAYBE IT WOULD BE INTERESTING TO CREATE CLASSES OF AGE SO WE CAN CLASSIFY 10 CLASSES: \n",
    "* 0-10\n",
    "* 20-30\n",
    "* 30-40\n",
    "* 40-50\n",
    "* 50-60\n",
    "* 60-70\n",
    "* 70-80\n",
    "* 80-90\n",
    "* 90-100\n",
    "* 100+"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f8a4fc",
   "metadata": {},
   "source": [
    "## KEEP IN MIND: DATA ANALYSIS\n",
    "\n",
    "## DATA AUGMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db62c312",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height = 200\n",
    "img_width = 200\n",
    "\n",
    "path = 'face_dataset/'\n",
    "ds_train = tf.data.Dataset.list_files(str(pathlib.Path(path+'*.jpg')))\n",
    "\n",
    "def process_path(file_path):\n",
    "    image = tf.io.read_file(file_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=1)\n",
    "    label = tf.strings.split(file_path, '\\\\')[1]\n",
    "    label = tf.strings.split(label, '_')[0]# First test: only Age \":2]\"\n",
    "    label = tf.strings.to_number(label, out_type=tf.int64)\n",
    "    \n",
    "    return image, label\n",
    "\n",
    "ds_train = ds_train.map(process_path).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f4fd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/building-a-multi-output-convolutional-neural-network-with-keras-ed24c7bc1178"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cf67c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b1e1e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a718d1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "xception = keras.applications.Xception(\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(img_height, img_width, 3),\n",
    "    include_top=False,\n",
    ")\n",
    "\n",
    "xception.trainable = False\n",
    "\n",
    "inputs = keras.Input(shape=(img_height, img_width, 3))\n",
    "\n",
    "x = xception(inputs, training=False)\n",
    "\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "x = keras.layers.Dropout(0.2)(x)\n",
    "\n",
    "x = keras.layers.Dense(1)(x)\n",
    "\n",
    "outputs = keras.layers.Activation('relu', name='age')(x)\n",
    "\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1f1fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = keras.optimizers.Adam(),\n",
    "    loss = keras.losses.MeanSquaredError(),\n",
    "    metrics = [keras.metrics.Accuracy()]\n",
    "    )\n",
    "\n",
    "history = model.fit(ds_train, epochs=5, validation_data=ds_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77618173",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d85794",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67797d2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f21334b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcdb5ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5eb970c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e56c37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66ef9caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open camera\")\n",
    "    exit()\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # if frame is read correctly ret is True\n",
    "        if not ret:\n",
    "            print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "            break\n",
    "        \n",
    "        faces = face_cascade.detectMultiScale(\n",
    "            frame,\n",
    "            scaleFactor=1.1,\n",
    "            minNeighbors=5,\n",
    "            flags=cv.CASCADE_SCALE_IMAGE\n",
    "        )\n",
    "        \n",
    "        for (x, y, w, h) in faces:\n",
    "            cv.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "        # Display the resulting frame\n",
    "        cv.imshow('frame', frame)\n",
    "        if cv.waitKey(1) == ord('q'):\n",
    "            break\n",
    "finally:\n",
    "    # Finally, release capture\n",
    "    cap.release()\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69147d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
